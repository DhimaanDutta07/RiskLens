# RiskLens â€” Fraud Guard ğŸ›¡ï¸

RiskLens is an end-to-end, production-style **fraud detection system** built to simulate a real fintech risk engine. It covers the full ML workflow: data â†’ feature engineering â†’ training â†’ evaluation â†’ explainability â†’ monitoring â†’ API â†’ interactive frontend.

This project is designed to be **action-based**, meaning the model is trained on transaction behavior signals and outputs a fraud probability that can be mapped to operational decisions (allow / review / block).

---

## âœ¨ Highlights

- INR-only fraud scoring pipeline (consistent feature distribution)
- Feature engineering system (fraud signals + composite risk score)
- Baseline model: Logistic Regression
- Main model: XGBoost
- Evaluation artifacts:
  - ROC curve, PR curve, confusion matrix
  - threshold selection (best-F1)
  - JSON report saved per model
- Explainability:
  - SHAP summary plot
  - top features exported as CSV
- Monitoring:
  - Evidently report for drift + classification performance
- Deployment-ready:
  - FastAPI inference API with CORS
  - Modern dark UI fraud console (interactive scenario builder)
- MLOps:
  - DVC pipeline (`dvc.yaml`)
  - MLflow experiment tracking
  - Docker support
  - GitHub Actions CI

---

## ğŸ“ Project Structure

RiskLens--Fraud-Guard/
â”œâ”€ api/ # FastAPI inference service
â”œâ”€ src/
â”‚ â”œâ”€ data/ # cleaning + splitting
â”‚ â”œâ”€ features/ # feature engineering
â”‚ â”œâ”€ models/ # preprocessing + training + evaluation
â”‚ â”œâ”€ explain/ # SHAP report
â”‚ â””â”€ monitoring/ # Evidently report
â”œâ”€ data/
â”‚ â”œâ”€ raw/ # raw dataset (DVC recommended)
â”‚ â””â”€ processed/ # engineered dataset (ignored in git)
â”œâ”€ artifacts/
â”‚ â”œâ”€ models/ # trained pipelines (.joblib)
â”‚ â”œâ”€ metrics/ # evaluation JSON reports
â”‚ â”œâ”€ graphs/ # ROC/PR/confusion/metric plots
â”‚ â”œâ”€ shap/ # SHAP summary + top features
â”‚ â””â”€ monitoring/ # Evidently HTML report
â”œâ”€ frontend/ # interactive fraud console
â”œâ”€ main.py # orchestrator (data/train/shap/monitor)
â”œâ”€ dvc.yaml # reproducible pipeline stages
â”œâ”€ Dockerfile
â””â”€ requirements.txt


---

## ğŸ”¢ Features Used

### Raw input features
- `event_time`
- `order_amount`
- `item_count`
- `ip_risk`, `device_risk`
- `billing_shipping_mismatch`, `shipping_address_changed`
- `email_verified`
- `account_age_days`
- `orders_last_7d`
- `failed_payments_last_24h`
- `distance_ip_to_shipping_km`
- `country`
- `payment_method`

### Engineered fraud signals
- `event_hour`, `unusual_time`
- `amount_inr`, `unusual_amount`
- `unusual_item_qty`
- `ip_risk_score`
- `shipping_risk_score`
- `new_account`
- `unusual_distance`
- `suspected_method`
- `unusual_orders_last_7d`
- `suspected_failed_payments_last_24h`
- `overall_risk_score`

---

## âš™ï¸ Setup

### Create virtual environment
```bash
python -m venv .venv
Activate
Windows

. .venv/Scripts/activate
Linux / Mac

source .venv/bin/activate
Install dependencies
pip install -r requirements.txt
ğŸš€ Run Pipeline
Run everything
python main.py --mode all
Run step-by-step
python main.py --mode data
python main.py --mode train
python main.py --mode shap
python main.py --mode monitor
ğŸ“Š Outputs (Artifacts)
After training, you will get:

Models
artifacts/models/logreg.joblib

artifacts/models/xgb.joblib

Metrics
artifacts/metrics/logreg.json

artifacts/metrics/xgb.json

Graphs
artifacts/graphs/*roc_curve.png

artifacts/graphs/*pr_curve.png

artifacts/graphs/*confusion.png

artifacts/graphs/*metrics_bar.png

SHAP
artifacts/shap/summary.png

artifacts/shap/top_features.csv

Monitoring
artifacts/monitoring/evidently_report.html

ğŸ§  MLflow Tracking
Training logs runs into ./mlruns automatically.

Start MLflow UI
mlflow ui --backend-store-uri ./mlruns --port 5001
Open:

http://127.0.0.1:5001
ğŸŒ Run the API (FastAPI)
Start server
uvicorn api.main:app --reload --port 8000
API base:

http://127.0.0.1:8000
ğŸ§ª Test with Postman
Health
GET

http://127.0.0.1:8000/health
Predict
POST

http://127.0.0.1:8000/predict
Body:

{
  "data": {
    "event_time": "2026-02-13 01:12:00",
    "order_amount": 47133,
    "currency": "INR",
    "country": "NG",
    "payment_method": "wallet",
    "item_count": 5,
    "ip_risk": 1,
    "device_risk": 1,
    "billing_shipping_mismatch": 1,
    "shipping_address_changed": 1,
    "email_verified": 0,
    "account_age_days": 5,
    "orders_last_7d": 44,
    "failed_payments_last_24h": 6,
    "distance_ip_to_shipping_km": 10210
  }
}
Debug engineered features
POST

http://127.0.0.1:8000/debug_features
ğŸ–¥ï¸ Frontend Console
Open:

frontend/index.html
The console:

lets you create high-risk scenarios

computes engineered columns automatically

sends full payload to the API

displays probability + risk band

ğŸ§© Reproducibility with DVC
Run pipeline using DVC:

dvc repro
ğŸ³ Docker
Build:

docker build -t risklens .
Run:

docker run -p 8000:8000 risklens
ğŸ”’ Notes
data/processed/, artifacts/, and mlruns/ should be ignored in git.

For large datasets, DVC is recommended.

Fraud probabilities may not always reach 0.9+ due to class imbalance; decision-making should use tuned thresholds.

ğŸ“Œ Author
Dhimaan Dutta
ML Engineering â€¢ Backend â€¢ MLOps â€¢ Fraud/Risk Systems

